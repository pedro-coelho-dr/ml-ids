
### 5. Multi-Layer Perceptron (MLP)

#### Configuração do Modelo

```python
best_clf = MLPClassifier(
    activation='tanh',
    hidden_layer_sizes=(100,),
    alpha=0.0001,
    batch_size=64,
    learning_rate_init=0.3,
    momentum=0.2,
    n_iter_no_change=20,
    max_iter=200,
    solver='sgd',
    early_stopping=True,
    random_state=1,
    verbose=False
)
```

#### Avaliação no Conjunto de Validação

| Métrica       | Valor   |
|---------------|---------|
| Acurácia      | 0.9957  |
| Precisão      | 0.9257  |
| Recall (TPR)  | 0.9129  |
| F1-score      | 0.9189  |
| RMSE          | 0.1758  |
| AUC (ROC)     | 0.9982  |

| Categoria | Precision | Recall | F1-score | Suporte |
|-----------|-----------|--------|----------|---------|
| DoS       | 0.9988    | 0.9995 | 0.9991   | 9186    |
| Probe     | 0.9940    | 0.9897 | 0.9918   | 2331    |
| R2L       | 0.8621    | 0.8794 | 0.8706   | 199     |
| U2R       | 0.7778    | 0.7000 | 0.7368   | 10      |
| normal    | 0.9961    | 0.9961 | 0.9961   | 13469   |

![](/report/img/mlp/1.png)  
![](/report/img/mlp/2.png)

#### Avaliação no Conjunto de Teste

| Métrica       | Valor   |
|---------------|---------|
| Acurácia      | 0.7597  |
| Precisão      | 0.8142  |
| Recall (TPR)  | 0.5679  |
| F1-score      | 0.6043  |
| FPR (média)   | 0.0808  |
| FNR (média)   | 0.4321  |
| RMSE          | 1.4296  |
| AUC (ROC)     | 0.9068  |

| Categoria | Precision | Recall | F1-score | Suporte |
|-----------|-----------|--------|----------|---------|
| DoS       | 0.9105    | 0.8172 | 0.8614   | 7458    |
| Probe     | 0.8262    | 0.6890 | 0.7514   | 2421    |
| R2L       | 0.9043    | 0.1244 | 0.2186   | 2887    |
| U2R       | 0.7600    | 0.2836 | 0.4130   | 67      |
| normal    | 0.6701    | 0.9253 | 0.7773   | 9711    |

![](/report/img/mlp/3.png)  


#### Observações

O MLP apresentou desempenho elevado na validação, com F1-score macro de 0.9189 e AUC de 0.9982. O modelo conseguiu bons resultados em todas as classes, inclusive R2L e U2R, que costumam ser desafiadoras.

No teste com KDDTest+, o modelo manteve um equilíbrio razoável. Destacaram-se os bons resultados para DoS (F1 = 0.86), Probe (F1 = 0.75), e normal (F1 = 0.77). R2L e U2R continuam difíceis. O recall médio foi de 0.57, e o AUC se manteve alto em 0.9068, sugerindo bom potencial para generalização mesmo diante de classes raras.
